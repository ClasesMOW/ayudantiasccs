---
title: "Datos observacionales y estrategias de identificación"
subtitle: "Ayudantía 2- Curso métodos en CCS"
author:
  name: Melanie Oyarzún
  affiliation: Universidad del Desarrollo
  email: moyarzunw@udd.cl
date: "`r format(Sys.time(), '%d %B %Y')`"

format: 
    html:
        theme: cosmo
        toc: true
        toc-depth: 3

editor: source

execute:
  eval: true
  warning: false
  

number-sections: false
crossref:
  chapters: true
---


# I. Bienvenida al tutorial

Hola, este tutorial está escrito como la actividad de aplicación de la ayudantía 2 del curso

La idea es ir desarrollando el tutorial en paralelo a la sesión y que puedan tomar apuntes adicionales directamente en el notebook. Está escrito como .qmd, un notebook Quarto y puede ser editado en restudio, vscode o cualquier otro IDE o editor de texto. El lenguaje utilizado para el procesamiento y análisis es R.

Se recomienda crear un fork al repositorio y trabajar en su propia rama.



**Como funciona**

-   El tutorial se estructura como un proyecto de investigación ficticio completo, que empezaremos cargando datos brutos hasta obtener e interpretar coficientes de regresión.

-   Lo métodos a cubir son:

    [1. Regresión lineal y método de diferencias (en datos experimentales)](#regresión-lineal-y-método-de-diferencias-en-datos-experimentales)

    [2. Logit y probit]

    [3. Variables Instrumentales]

    [4. Regresión Discontinua]

    [5. Diferencias en Diferencias]

    [6. Efectos fijos, aleatorios y modelos jerárquicos]

    [7. Matching]

-   Los datos y notebook son descargables, así que se recomienda correr todo en tu propio computador o en una instancia en la nube.

-   Este tutorial es una adaptación del trabajo de [Hans H. Sievertsen](https://hhsievertsen.shinyapps.io/applied_econ_with_R_dynamic), con la adición de métodos de matching y con cambios a la situación a analizar.

<br>

## 1 Pregunta de investigación y datos

Vamos a usar una situación ficticia, con datos simulados para poder aplicar de manera consisa los diferentes tipos de estrategias de identificación revisadas en clase. ALgunas (que se supone ya manejan) las revisaremos muy rápidamente y en otras, vamos a tener mayor énfasis.

### 1.1 Pregunta de investigación

Nuestro objetivo es responder la siguiente pregunta **ficticia** de investigación:

> Asistir a preuniversitario mejora los resultados académicos?

Para responder esta pregunta, usaremos unos datos **ficticios y simulados**

### 1.2 Contexto ficticio

La pregunta de investigación

The research question is inspired by papers such as [Matsudaira (2007)](https://www.sciencedirect.com/science/article/pii/S0304407607001194?casa_token=hnnF764CKPoAAAAA:5b9WhCManNDsdW4SmOHnnzNr0fZIarW8s6EsvpQW7MdUt470eNPmN2T8IFCsNc6Iajew5tEeNA) and the survey on interventions for low SES students by by [Dietrichson et al ( 2017)](https://journals.sagepub.com/doi/abs/10.3102/0034654316687036).

El **escenario ficticio** es el siguiente:

-   Para un conjunto de colegios en una comuna, existe la opción de asistir a pre-unirversitario intensivo los fines de semana durante el segundo semestre de 4to medio.
-   El preuniversitario se enfoca en preparar la prueba de admisión a la universidad vigente (PSU en ese momento)
-   El preuniversitario es gratuito, pero para ser matriculados requiere que los padres se involucren en un proceso.
-   Estamos interesados en testear el impacto de la participación en el preuniversitario en los resultados académicos de los estudiantes.

### 1.3 Datos ficticios dispobibles

1. school_data_1.csv
- Usamos esta data para ejemplificar como cargar data guardada en formato csv.
- Este dataset tiene información sobre cada individuo (con identificador id), la escuela a la que asiste, un indicador si participó en el preuniversitario, sexo, ingreso del hogar, educación de los padres, resultados en diagnostico PSU a incios del año escolar y el puntaje efectivamente obtenido en la prueba oficial.

2. school_data_2.dta
- Usamos esta data para ejemplificar como cargar data guardada en formato STATA.
- Este dataset tiene información de cada individuo (con identificador id).
- Este dataset tiene la información si el individuo recibió la carta de invitación para participar del preuniversitario.

3. school_data_3.xlsx
- Usamos este dataset para practicar como cargar datos guardados en formato Microsoft Excel.
- Este dataset incluye datos sobre cada individuo (con identificador id)
- Este dataset tiene información de rendimiento académico antes y después del preuniversitario.


# II. Preparación de los datos

En esta sección vamos a preparar los datos para el análisis. Este proceso generalmente incluye cargarlos, inspeccionarlos, limpiar y dar la estructura deseada.  También revisaremos estadísticas descriptivas que nos den una idea antes de estimar cualquier modelo.

En la vida real, este proceso suele ser bastante largo, laborioso e implica volver sobre lso pasos anteriores múltiples veces. También invlocura tomar desiciones por parte de los investigadores, por lo cual la documentación de esta fase es especialmente importante.

En nuestro caso, será bastante lineal y directo, ya que son datos ficticios simulados. Pero en la realidad, no suele ser así.

## 1 Cargar los datos

### 1.1 Intalar y cargar paquetes

Para poder cargar los datos, necesiamos los paquetes adecuados. Siempre hay multiples formas de hacer las cosas en cualquier lenguaje o programa. En este caso, usaremos la función `read_csv()` del paquete *readr*. 
Para poder usarlo, debemos estar seguros de que está instalado. 


```{r}

```


Si no está instalado, podemos hacerlo con la función `install.packages("[nombre paquete a instalar]")`


```{r}
#| eval: false

install.packages("readr")
```


Si el paquete ya está instalado, para poder usarlo necesitamos tenerlo cargado en nuestra librería. Para esto usamos la función  `library("[nombre paquete a cargar]")`.



```{r}
library(readr)
```


Cada paquete lo debemos instalar solo una vez por computador, pero debemos cargarlo en cada sesión para poder utilizarlo.


### 1.2 Cargar datos csv

Con *readr* estamos en condiciones de usar la función `read_csv()` para cargar la primera base de datos.

Vamos a cargar *school_data_1.csv* agregando el path a los datos en paréntesis.  Puede reemplazar por el path correspondiente o usar el paquete auxiliar `here`

by inserting the path to the file in the parenthesis. In the example below we first load the *readr* package to illustrate that we have to load it in every new session. However, in later code blocks we'll leave out the `library()` call for packages that have already been loaded.

PS. note also that we include comments in code block below. Comments are lines that R ignores and these lines always start with a `#` symbol.


```{r ch2-3 }
#| warning: false

# load readr package
library("readr", "here")

#prueba el directorio que te dice con here
here::here()
```


Entonces, dentro de here("[Escribes el directorio relativo]") actuará como el directorio relativo sin errores. Entonces, cargamos los datos y los asignamos a un data frame.


```{r}

school_data_1 <- read.csv(here::here("data_raw/school_data_1.csv"))

```


Usualmente, después de cargar un dataset es ´til visiualizarlo. Usamos ka función head para ver sus primeras 6 observaciones.


```{r ch2-3a}
#| warning: false
#| eval: true

head(school_data_1)

```


Una segunda alternativa es descargar y cargar los datos directamente en R desde internet. Puede ser cualquier link directo o, si está alojado en github, tiene que ser un repo público.



```{r}
#| eval: false

school_data_1 <- read.csv("https://github.com/ClasesMOW/ayudantiasccs/blob/main/data_raw/school_data_1.csv")
```



### 1.3 Cargar datos STATA

En Ciencias Sociales es muy comun contar con datos para ser utilizados en el programa stata, estos terminan en .dta. Para cargarlos, 

```{r}

school_data_1 <- read.csv(here::here("data_raw/school_data_1.csv"))

```


https://github.com/ClasesMOW/ayudantiasccs/blob/main/data_raw/school_data_2.dta

Vamos a usar HAVEN del paquete tidyverse. Tambien usaremos muchas otras funciones de ese paquete, asi que es buen momento para cargalo.


```{r}
library(tidyverse)

school_data_2<- haven::read_dta(here::here("data_raw/school_data_2.dta"))
```


Usemos el comando tail() para ver las últimas 10 entradas.


```{r}
# print the 8 rows in the tail
tail(school_data_2,n=10)
```


### 1.4 Cargar datos Microsoft Excel

Finalmente, cargaremos el tercer dataset .xlsx. Para esto usaremos tambien del paquete readxl que viene incluido en tidyverse. Démosle una mirada con glimpse, también del tidyverse.


```{r}
school_data_3 <- readxl::read_xlsx(here::here("data_raw/school_data_3.xlsx"))

glimpse(school_data_3)
```



## 2. Unir los datasets

Tenemos 3 bases de datos con información diferente de los ismos individuos. Tal vez quisieramos tener una sola gran tabla comn toda esta información.

La base de datos 1 y 2 tienen una forma similar: los individuos son filas y las variables columnas y hay una sola fila para cada individuo.

Para hacerlo, podriamos usar varias alternativas. 

Una alternativa es usar la función nativa merge( )¨




Otra opción es con join de tidyverse.




## 3. Lipiar los datos




# III. Estimación e identifiación

## 1. Regresión lineal y método de diferencias (en datos experimentales) {#regresión-lineal-y-método-de-diferencias-en-datos-experimentales}

## 2. Logit y probit {#logit-y-probit}

## 3. Variables Instrumentales

## 4. Regresión Discontinua

## 5. Diferencias en Diferencias

## 6. Efectos fijos, aleatorios y modelos jerárquicos

## 7. Matching

